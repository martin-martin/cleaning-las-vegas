{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Las Vegas\n",
    "\n",
    "My flight to arrive in the USA went to Las Vegas, so it was the first city I spent some time in.\n",
    "\n",
    "I got myself a cheap bed in the suburbs close to the airport, and started working on my DAND P3, cleaning OSM data. Since I was here, and found the idea exciting, I downloaded the MetroExtract of Las Vegas: https://s3.amazonaws.com/metro-extracts.mapzen.com/las-vegas_nevada.osm.bz2 and went on my task to discover the city I was staying in through Data Science. :)\n",
    "\n",
    "Here are the results of a wrangling process that lasted much longer than my stay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size in Bytes: 184636412\n",
      "File Size in MB:    176\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "las_vegas_osm = 'las-vegas_nevada.osm'\n",
    "## for testing and developing purposes, uncomment the truncated version:\n",
    "#las_vegas_osm = 'LV_truncated.osm'\n",
    "file_size = os.path.getsize(las_vegas_osm)\n",
    "print 'File Size in Bytes:', file_size\n",
    "print 'File Size in MB:   ', file_size / (2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    '''Creates a dictionary with the tags present in the dataset, alongside a count for each'''\n",
    "    tag_dict = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag not in tag_dict:\n",
    "            tag_dict[elem.tag] = 1\n",
    "        elif elem.tag in tag_dict:\n",
    "            tag_dict[elem.tag] += 1\n",
    "    return tag_dict\n",
    "\n",
    "las_vegas_osm_dict = count_tags(las_vegas_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bounds           1\n",
       "member        3158\n",
       "nd          995111\n",
       "node        824219\n",
       "osm              1\n",
       "relation       316\n",
       "tag         545013\n",
       "way          92487\n",
       "Name: tags and their amounts, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "las_vegas_osm_tags = pd.Series(las_vegas_osm_dict, name='tags and their amounts')\n",
    "las_vegas_osm_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The city is big. Not only in bytes.\n",
    "\n",
    "For quite a long time I took digital walks, checking through querying the dataset which places exist and what could be an interesting spot. Sometimes I took a real-life walk to find those places, often I remained online and went to check them out with an online map utility.\n",
    "\n",
    "During my exploration I wondered what and where are the **bays** in Las Vegas, whether there is **grass**(parks) to find anywhere, where is that one lonely **picnic_table**, and where would I be able to get my longed-for fatty US-style **pizza**.\n",
    "\n",
    "I also discovered the **TIGER** data that a lot of OSM's street data had been imported from. At first I had no idea what this is about, but with the help of the OSM wiki and some additional research, I started to understand. I also spent a while writing functions that were fetching the different parts of the TIGER data and concatenating it properly to write the missing ` addr:street ` tags and fill their values with what I had programatically stuck together. Shortly after managing, I realized that there was a `name` attribute to one tag in each way Element, that held exactly this data that I had created...\n",
    "\n",
    "If you are interested in this phase of my explorations, you can find more talking (and code!) here:\n",
    "https://github.com/martin-martin/cleaning-las-vegas/blob/master/las_vegas.ipynb. It reads a little bit like a blog, I think :)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More focused Exploring\n",
    "\n",
    "So I started a new notebook. I focused on looking for the street types as suggested in the course material. Now I also knew in which tag to search for them... :)\n",
    "\n",
    "I audited the street names and ended up with a long list of messiness.\n",
    "\n",
    "Then, step by step, I took out those street types that were common, and explored further examples of other \"street types\", or \"ways\", that seemed suspicious to me for maybe _not being ways_.\n",
    "\n",
    "OSM uses the \"way\" tag also for something called an **area**, which can e.g. be a building or a park - basically anything for which it is interesting to preserve its shape. An area is constructed of closed ways: http://wiki.openstreetmap.org/wiki/Area. Here's, as an example, the description for buildings: http://wiki.openstreetmap.org/wiki/Relations/Proposed/Buildings\n",
    "\n",
    "Using the IDs extracted from the dataset and tapped together with the suspicious \"street\" name into a dictionary, I went to check some of those way tags online, such as: http://www.openstreetmap.org/way/134574757\n",
    "\n",
    "This is, yes indeed: a **golf course**. One that, however, nowhere mentions that it is a golf course...\n",
    "\n",
    "Here's a link to that new file of exploration:\n",
    "\n",
    "And the following code is the revisited version of what I was doing there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "def audit_street_type(street_types, expected, street_name):\n",
    "    street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "    found = street_type_re.search(street_name)\n",
    "    if found:\n",
    "        street_type = found.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type not in street_types:\n",
    "                street_types[street_type] = [street_name]\n",
    "            else:\n",
    "                street_types[street_type].append(street_name)\n",
    "\n",
    "def collect_way_types(filename, expected_types):\n",
    "    street_types = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start',)):\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if tag.attrib['k'] == 'name':\n",
    "                    street_name = tag.attrib['v']\n",
    "                    audit_street_type(street_types, expected_types, street_name)                       \n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choosing to exclude the common street types\n",
    "common_types = []\n",
    "street_types = collect_way_types(las_vegas_osm, common_types)\n",
    "# While working with the truncated version of the dataset,\n",
    "# I chose the threshold of 7 through checking the results. \n",
    "# 10 returned an empty list, 5 included 'Vegas' :)\n",
    "threshold = 7\n",
    "for key, value in street_types.items():\n",
    "    if len(value) > threshold:\n",
    "        common_types.append(key)   \n",
    "    \n",
    "street_types = collect_way_types(las_vegas_osm, common_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(street_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It becomes obvious that this is a crazy amount of Elements that are considered 'ways', but are obviously not streets. While working on my project with the truncated version of the dataset, these \"special\" instances were fewer, but still quite many.\n",
    "\n",
    "I went down the path of trying to programmatically exclude and/or clean those special cases to individually reduce this list of 'ways' that have not a street type as their name ending.\n",
    "\n",
    "**I would not do this again.** It is exciting, because one can discover a lot, but it is very ineffective.\n",
    "\n",
    "Instead I would adapt the `audit_street_type()` function in order to be better adapted to my dataset. Here there were few Elements labeled with the `addr:street` key, but the street name data was often saved in the `name` attribute. However, as the length of the \"`street_types`\" dictionary shows, also many other things utilize the `name` attribute.\n",
    "\n",
    "Anyways. I paid with time, that I invested in a journey of learning and discovery. :)\n",
    "This is not the worst currency, at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my investigation of the individual suspicious entries, I've used the following function in combination with checking the ID online with OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_something(filename, regex):\n",
    "    '''Prints all XML elements matching the specified regex somewhere in their tags, \n",
    "    and a link to the specific OSM way. Returns None.'''\n",
    "    import re\n",
    "    flag = False\n",
    "    for event, elem in ET.iterparse(filename, events=('start',)):\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if tag.attrib['k'] == 'name':\n",
    "                    if re.search(regex, ET.tostring(tag)):\n",
    "                        print \"Check ID online at: http://www.openstreetmap.org/way/\" + elem.attrib['id'] + '\\n'\n",
    "                        ET.dump(elem)\n",
    "                        flag = True\n",
    "    if not flag:\n",
    "        print \"No matching Element was found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would produce e.g. the following result - allowing me to check the Element (and especially its attributes) also if I had no internet connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/14308393\n",
      "\n",
      "<way changeset=\"631433\" id=\"14308393\" timestamp=\"2007-11-27T16:21:07Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\t\t<nd ref=\"137515455\" />\n",
      "\t\t<nd ref=\"137432296\" />\n",
      "\t\t<tag k=\"name\" v=\"Perfect Waters\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t\t<tag k=\"tiger:cfcc\" v=\"A41\" />\n",
      "\t\t<tag k=\"tiger:tlid\" v=\"201947443\" />\n",
      "\t\t<tag k=\"tiger:county\" v=\"Clark, NV\" />\n",
      "\t\t<tag k=\"tiger:source\" v=\"tiger_import_dch_v0.6_20070813\" />\n",
      "\t\t<tag k=\"tiger:reviewed\" v=\"no\" />\n",
      "\t\t<tag k=\"tiger:name_base\" v=\"Perfect Waters\" />\n",
      "\t\t<tag k=\"tiger:separated\" v=\"no\" />\n",
      "\t\t<tag k=\"tiger:upload_uuid\" v=\"bulk_upload.pl-fa98df75-5974-4c49-9081-f3ca4b3c7383\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "find_something(las_vegas_osm, 'Perfect Waters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've run quite a few of those queries, which are of course very labour-intensive.\n",
    "This is what I call already my _more focused_ exploration :)\n",
    "\n",
    "But I felt I needed to understand what are some of these places, so that I'd know how to deal with them later on. Also, it helped me to better get to know Las Vegas and the OpenStreetMap project.\n",
    "\n",
    "Here's an intermediate result, that allowed me to reduce the size of the street type dictionary a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these can be safely excluded, because they represent (most probably) valid ways\n",
    "valid_ways = ['Aisle', 'Alley', 'Bypass', 'Channel', 'Highway', 'Interconnect', 'Loop', 'Monorail', 'Path', 'Paths',\n",
    "             'Route', 'Speedway', 'Walk']\n",
    "nature_ways = ['Falls', 'Forest', 'Lake', 'Shore', 'Spillway', 'Stream', 'River', 'Thrust', 'Wash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = common_types + valid_ways + nature_ways\n",
    "street_types =  collect_way_types(las_vegas_osm, exclude)\n",
    "len(street_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've come to encounter quite some beautiful street names along my exploration. Some are emotional, others telling, or also sad - because their names are so opposite of how they probably look in reality.\n",
    "\n",
    "Here are some examples of those that I -saw and liked:\n",
    "\n",
    "- Willow Wisp Terrace\n",
    "- Wonderful Day Drive\n",
    "- Perfect Waters\n",
    "- Wanderlust\n",
    "- Whisper Reef\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Clean a bit\n",
    "\n",
    "So I decided it was time to try to reduce the mess I had found, at least a tiny bit.\n",
    "\n",
    "There were two possibilities I saw myself deciding between:\n",
    "\n",
    "1. performing all cleaning on the original document, or \n",
    "2. filtering the database step by step, reducing its size, then performing cleaning steps on the singled-out Elements, and finally writing them back into the original Element Tree.\n",
    "\n",
    "It felt that I could learn more with the second approach. I also thought that it would allow me to discover problems that I wouldn't have thought about myself. This makes the cleaning task more thorough ( - but also much more tedious...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing to 'way' tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reduced the size of the Element Tree by \n",
    "\n",
    "- first extracting only the 'way' tags, \n",
    "- then by excluding common and well-spelled street names, \n",
    "- and even further by excluding some other uses of 'way' tags that were actually not streets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference: https://discussions.udacity.com/t/changing-attribute-value-in-xml/44575/6\n",
    "from pprint import pprint\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "OSM_FILE = las_vegas_osm\n",
    "NEW_FILE = 'cleaning_1.osm'\n",
    "\n",
    "def get_ways(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Filters an OSM file and yields the 'way' elements.\"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            if elem.tag == 'way':\n",
    "                yield elem\n",
    "                root.clear()\n",
    "\n",
    "with open(NEW_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    for i, element in enumerate(get_ways(OSM_FILE)):\n",
    "        output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding common street types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting the input file to the previous output file\n",
    "OSM_FILE = NEW_FILE\n",
    "NEW_FILE = 'cleaning_2.osm'\n",
    "common_and_valid_ways = exclude\n",
    "\n",
    "def select_some_way_elems(osm_file, excluded_ways):\n",
    "    \"\"\"Yields way elements which last word (usually the street type) is not in a list to exclude.\"\"\"\n",
    "    import re\n",
    "    street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "    \n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag == 'way':\n",
    "            for tag in elem.iter():\n",
    "                try:\n",
    "                    if tag.attrib['k'] == 'name':\n",
    "                        street_name = tag.attrib['v'] \n",
    "                        found = street_type_re.search(street_name)\n",
    "                        street_type = found.group()\n",
    "                        if street_type not in excluded_ways:\n",
    "                            yield elem\n",
    "                            root.clear()\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "# here I write a new document consisting only of those way elements that select_some_way_elems() yields.\n",
    "with open(NEW_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    for i, element in enumerate(select_some_way_elems(OSM_FILE, common_and_valid_ways)):\n",
    "        output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the street names\n",
    "\n",
    "Having reduced the size of my dataset, I started to write the functions which eventually would allow me to clean it a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_file(filename, function, *args):\n",
    "    \"\"\"Modifies a file according to the output of a function.\n",
    "    \n",
    "    Takes as input a file name, a function and its arguments.\n",
    "    Runs the (cleaning) function and writes the output back into the file,\n",
    "    using a temporary file object as intermediate step.\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/17646680/writing-back-into-the-same-file-after-reading-from-the-file\n",
    "    \"\"\"\n",
    "    import tempfile\n",
    "    import sys\n",
    "    temp_file = tempfile.NamedTemporaryFile(mode = 'r+')\n",
    "    input_file = open(filename, 'r')\n",
    "    for i, element in enumerate(function(*args)):\n",
    "        temp_file.write(ET.tostring(element, encoding='utf-8'))\n",
    "    input_file.close()\n",
    "    temp_file.seek(0)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        f.write('<osm>\\n  ')\n",
    "        for line in temp_file:\n",
    "            f.write(line)\n",
    "        f.write('</osm>')\n",
    "    temp_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute_attrib_value(osm_file, before, after, attrib_key, tags=('way', 'node', 'relation')):\n",
    "    \"\"\"Changes text in an attribute to a string defined in 'after'.\n",
    "\n",
    "    Changes the text in a specified attribute of a 'way' tag \n",
    "    that contains the string variable defined in 'before' for a new string defined in 'after'.\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/changing-attribute-value-in-xml/44575/6\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            if elem.tag == 'way':\n",
    "                for tag in elem.iter('tag'):\n",
    "                    # not changing the original TIGER data\n",
    "                    if ('tiger:' not in tag.attrib['k'] and \n",
    "                        re.search(before, ET.tostring(tag))):\n",
    "                        tag.set(attrib_key, after)\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute_smth(osm_file, before, after, attrib_key):\n",
    "    \"\"\"Wrapper function: Calls substitute_attrib_value() and modify_file().\n",
    "    \n",
    "    Substitutes a 'way' tag attribute for another and writes the changes back.\n",
    "    \"\"\"\n",
    "    substitute_attrib_value(osm_file, before, after, attrib_key, tags=('way', 'node', 'relation'))\n",
    "    modify_file(osm_file, substitute_attrib_value, osm_file, before, after, attrib_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this wrapper function allows me to do corrections for misspelled street names, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting the input file to the previous output file\n",
    "OSM_FILE = 'cleaning_2.osm'\n",
    "\n",
    "substitute_smth(OSM_FILE, 'Wonderful Day Driive', 'Wonderful Day Drive', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the adaptation, here's the check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching Element was found.\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Wonderful Day Driive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/98572517\n",
      "\n",
      "<way changeset=\"24413704\" id=\"98572517\" timestamp=\"2014-07-29T02:09:10Z\" uid=\"3392\" user=\"SimMoonXP\" version=\"4\">\n",
      "\t\t<nd ref=\"1140354752\" />\n",
      "\t\t<nd ref=\"1140354845\" />\n",
      "\t\t<nd ref=\"1140354771\" />\n",
      "\t\t<nd ref=\"1140354747\" />\n",
      "\t\t<nd ref=\"1140354413\" />\n",
      "\t\t<nd ref=\"1140354415\" />\n",
      "\t\t<nd ref=\"1140354456\" />\n",
      "\t\t<nd ref=\"1140354488\" />\n",
      "\t\t<nd ref=\"1140354517\" />\n",
      "\t\t<nd ref=\"1140354819\" />\n",
      "\t\t<nd ref=\"1140354655\" />\n",
      "\t\t<nd ref=\"1140354561\" />\n",
      "\t\t<nd ref=\"1140354881\" />\n",
      "\t\t<nd ref=\"1140354859\" />\n",
      "\t\t<nd ref=\"1140354611\" />\n",
      "\t\t<nd ref=\"1140354861\" />\n",
      "\t\t<nd ref=\"1140354615\" />\n",
      "\t\t<nd ref=\"1140354610\" />\n",
      "\t\t<nd ref=\"1140354609\" />\n",
      "\t\t<nd ref=\"1140354497\" />\n",
      "\t\t<nd ref=\"1140354490\" />\n",
      "\t\t<nd ref=\"1140354498\" />\n",
      "\t\t<nd ref=\"1140354864\" />\n",
      "\t\t<nd ref=\"1140354863\" />\n",
      "\t\t<nd ref=\"1140354867\" />\n",
      "\t\t<nd ref=\"1140354633\" />\n",
      "\t\t<nd ref=\"1140354821\" />\n",
      "\t\t<nd ref=\"1140354895\" />\n",
      "\t\t<nd ref=\"1140354865\" />\n",
      "\t\t<nd ref=\"1140354678\" />\n",
      "\t\t<nd ref=\"1140354547\" />\n",
      "\t\t<nd ref=\"1140354780\" />\n",
      "\t\t<nd ref=\"1140354409\" />\n",
      "\t\t<nd ref=\"1140354411\" />\n",
      "\t\t<nd ref=\"1140354889\" />\n",
      "\t\t<nd ref=\"1140354659\" />\n",
      "\t\t<nd ref=\"1140354566\" />\n",
      "\t\t<nd ref=\"1140354649\" />\n",
      "\t\t<nd ref=\"1140354474\" />\n",
      "\t\t<nd ref=\"1140354569\" />\n",
      "\t\t<nd ref=\"1140354626\" />\n",
      "\t\t<nd ref=\"1140354755\" />\n",
      "\t\t<nd ref=\"1140354480\" />\n",
      "\t\t<nd ref=\"1140354579\" />\n",
      "\t\t<nd ref=\"1140354416\" />\n",
      "\t\t<nd ref=\"1140354482\" />\n",
      "\t\t<nd ref=\"1140354832\" />\n",
      "\t\t<nd ref=\"1140354644\" />\n",
      "\t\t<nd ref=\"1140354896\" />\n",
      "\t\t<nd ref=\"1140354495\" />\n",
      "\t\t<nd ref=\"1140354602\" />\n",
      "\t\t<tag k=\"name\" v=\"Wonderful Day Drive\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Wonderful Day Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_attribute(osm_file, elem_id, attrib_key, attrib_value, tags=('way', 'node', 'relation')):\n",
    "    '''Adds a tag Element with attribute and value to a 'way' Element specified through an ID.\n",
    "\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/changing-attribute-value-in-xml/44575/6\n",
    "    '''\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            if elem.attrib['id'] == elem_id:\n",
    "                try:\n",
    "                    for tag in elem.iter('tag'):\n",
    "                        if tag.attrib['k'] == attrib_key and tag.attrib['v'] == attrib_value:\n",
    "                            raise Exception('AttributePresentError')\n",
    "                    ET.SubElement(elem, 'tag', k=attrib_key, v=attrib_value)\n",
    "                except Exception:\n",
    "                    print \"The attributes %s=%s are already present in this Element.\"%(attrib_key, attrib_value)\n",
    "                    continue\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_smth(osm_file, elem_id, attrib_key, attrib_value):\n",
    "    '''Wrapper function: Calls add_attribute() and modify_file().\n",
    "    \n",
    "    Adds an attribute with value to an existing \"way\" tag, writes the changed ET back to the file.'''\n",
    "    \n",
    "    add_attribute(osm_file, elem_id, attrib_key, attrib_value, tags=('way', 'node', 'relation'))\n",
    "    modify_file(osm_file, add_attribute, osm_file, elem_id, attrib_key, attrib_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions allow me to add tags to describe that some 'ways' are actually _buildings_ or other _areas_. E.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/27575068\n",
      "\n",
      "<way changeset=\"15877547\" id=\"27575068\" timestamp=\"2013-04-26T22:01:01Z\" uid=\"63936\" user=\"MojaveNC\" version=\"4\">\n",
      "\t\t<nd ref=\"2282598954\" />\n",
      "\t\t<nd ref=\"2282599039\" />\n",
      "\t\t<nd ref=\"302766150\" />\n",
      "\t\t<nd ref=\"1495619638\" />\n",
      "\t\t<nd ref=\"1495619718\" />\n",
      "\t\t<nd ref=\"302766151\" />\n",
      "\t\t<nd ref=\"302766153\" />\n",
      "\t\t<nd ref=\"302766154\" />\n",
      "\t\t<nd ref=\"302766156\" />\n",
      "\t\t<nd ref=\"302766157\" />\n",
      "\t\t<nd ref=\"302766158\" />\n",
      "\t\t<nd ref=\"1431998076\" />\n",
      "\t\t<nd ref=\"2282598955\" />\n",
      "\t\t<nd ref=\"2282598945\" />\n",
      "\t\t<nd ref=\"2282598949\" />\n",
      "\t\t<nd ref=\"2282598954\" />\n",
      "\t\t<tag k=\"name\" v=\"Green Valley Country Club Apts.\" />\n",
      "\t\t<tag k=\"landuse\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Green Valley Country Club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_smth(OSM_FILE, '27575073', 'building', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/27575068\n",
      "\n",
      "<way changeset=\"15877547\" id=\"27575068\" timestamp=\"2013-04-26T22:01:01Z\" uid=\"63936\" user=\"MojaveNC\" version=\"4\">\n",
      "\t\t<nd ref=\"2282598954\" />\n",
      "\t\t<nd ref=\"2282599039\" />\n",
      "\t\t<nd ref=\"302766150\" />\n",
      "\t\t<nd ref=\"1495619638\" />\n",
      "\t\t<nd ref=\"1495619718\" />\n",
      "\t\t<nd ref=\"302766151\" />\n",
      "\t\t<nd ref=\"302766153\" />\n",
      "\t\t<nd ref=\"302766154\" />\n",
      "\t\t<nd ref=\"302766156\" />\n",
      "\t\t<nd ref=\"302766157\" />\n",
      "\t\t<nd ref=\"302766158\" />\n",
      "\t\t<nd ref=\"1431998076\" />\n",
      "\t\t<nd ref=\"2282598955\" />\n",
      "\t\t<nd ref=\"2282598945\" />\n",
      "\t\t<nd ref=\"2282598949\" />\n",
      "\t\t<nd ref=\"2282598954\" />\n",
      "\t\t<tag k=\"name\" v=\"Green Valley Country Club Apts.\" />\n",
      "\t\t<tag k=\"landuse\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Green Valley Country Club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id(filename, regex):\n",
    "    '''Returns a list of the IDs of the element(s) matching the specified regex somewhere in their tags.'''\n",
    "    import re\n",
    "    elem_id_list = []\n",
    "    for event, elem in ET.iterparse(filename, events=('start',)):\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if tag.attrib['k'] == 'name':\n",
    "                    if re.search(regex, ET.tostring(tag)):\n",
    "                        elem_id_list.append(elem.attrib['id'])\n",
    "    return elem_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for area in street_types['Estates']:\n",
    "    for elem_id in get_id(OSM_FILE, area):\n",
    "        add_smth(OSM_FILE, elem_id, 'place', 'suburb')\n",
    "        add_smth(OSM_FILE, elem_id, 'area', 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual changes for specific streets\n",
    "\n",
    "Some street names are simply missing their street type as an ending. I've double-checked these places with OSM through their ID and with GoogleMaps. If it addressed the same street and there was a street type extension in GoogleMaps, I added it to the data (not sure whether this is legal?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/203447533\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447533\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638188\" />\n",
      "\t\t<nd ref=\"2134638182\" />\n",
      "\t\t<nd ref=\"2134638168\" />\n",
      "\t\t<nd ref=\"2134638153\" />\n",
      "\t\t<nd ref=\"2134638146\" />\n",
      "\t\t<nd ref=\"2134638141\" />\n",
      "\t\t<nd ref=\"2134638136\" />\n",
      "\t\t<nd ref=\"2134638135\" />\n",
      "\t\t<nd ref=\"2134638139\" />\n",
      "\t\t<nd ref=\"2134638144\" />\n",
      "\t\t<nd ref=\"2134638150\" />\n",
      "\t\t<nd ref=\"2134638159\" />\n",
      "\t\t<nd ref=\"2134638173\" />\n",
      "\t\t<nd ref=\"2134638183\" />\n",
      "\t\t<nd ref=\"2134638189\" />\n",
      "\t\t<nd ref=\"2134638191\" />\n",
      "\t\t<nd ref=\"2134638194\" />\n",
      "\t\t<nd ref=\"2134638193\" />\n",
      "\t\t<nd ref=\"2134638188\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/203447566\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447566\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<nd ref=\"2134638161\" />\n",
      "\t\t<nd ref=\"2134638153\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/203447571\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447571\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638182\" />\n",
      "\t\t<nd ref=\"2134638178\" />\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/210560329\n",
      "\n",
      "<way changeset=\"15393235\" id=\"210560329\" timestamp=\"2013-03-17T09:49:17Z\" uid=\"12434\" user=\"nm7s9\" version=\"1\">\n",
      "\t\t<nd ref=\"2134638315\" />\n",
      "\t\t<nd ref=\"2134638310\" />\n",
      "\t\t<nd ref=\"2134638277\" />\n",
      "\t\t<nd ref=\"2134638249\" />\n",
      "\t\t<nd ref=\"2134638237\" />\n",
      "\t\t<nd ref=\"2134638230\" />\n",
      "\t\t<nd ref=\"2134638224\" />\n",
      "\t\t<nd ref=\"2134638221\" />\n",
      "\t\t<nd ref=\"2134638220\" />\n",
      "\t\t<nd ref=\"2134638223\" />\n",
      "\t\t<nd ref=\"2134638229\" />\n",
      "\t\t<nd ref=\"2134638233\" />\n",
      "\t\t<nd ref=\"2134638243\" />\n",
      "\t\t<nd ref=\"2134638259\" />\n",
      "\t\t<nd ref=\"2134638322\" />\n",
      "\t\t<nd ref=\"2134638403\" />\n",
      "\t\t<nd ref=\"2134638410\" />\n",
      "\t\t<nd ref=\"2134638413\" />\n",
      "\t\t<nd ref=\"2134638416\" />\n",
      "\t\t<nd ref=\"2134638414\" />\n",
      "\t\t<nd ref=\"2134638412\" />\n",
      "\t\t<nd ref=\"2134638407\" />\n",
      "\t\t<nd ref=\"2134638402\" />\n",
      "\t\t<nd ref=\"2134638396\" />\n",
      "\t\t<nd ref=\"2134638390\" />\n",
      "\t\t<nd ref=\"2134638373\" />\n",
      "\t\t<nd ref=\"2134638304\" />\n",
      "\t\t<nd ref=\"2134638257\" />\n",
      "\t\t<nd ref=\"2134638238\" />\n",
      "\t\t<nd ref=\"2134638226\" />\n",
      "\t\t<nd ref=\"2134638210\" />\n",
      "\t\t<nd ref=\"2134638202\" />\n",
      "\t\t<nd ref=\"2134638192\" />\n",
      "\t\t<nd ref=\"2134638185\" />\n",
      "\t\t<nd ref=\"2134638180\" />\n",
      "\t\t<nd ref=\"2134638172\" />\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Wanderlust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'Wanderlust', 'Wanderlust Court', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/203447533\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447533\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638188\" />\n",
      "\t\t<nd ref=\"2134638182\" />\n",
      "\t\t<nd ref=\"2134638168\" />\n",
      "\t\t<nd ref=\"2134638153\" />\n",
      "\t\t<nd ref=\"2134638146\" />\n",
      "\t\t<nd ref=\"2134638141\" />\n",
      "\t\t<nd ref=\"2134638136\" />\n",
      "\t\t<nd ref=\"2134638135\" />\n",
      "\t\t<nd ref=\"2134638139\" />\n",
      "\t\t<nd ref=\"2134638144\" />\n",
      "\t\t<nd ref=\"2134638150\" />\n",
      "\t\t<nd ref=\"2134638159\" />\n",
      "\t\t<nd ref=\"2134638173\" />\n",
      "\t\t<nd ref=\"2134638183\" />\n",
      "\t\t<nd ref=\"2134638189\" />\n",
      "\t\t<nd ref=\"2134638191\" />\n",
      "\t\t<nd ref=\"2134638194\" />\n",
      "\t\t<nd ref=\"2134638193\" />\n",
      "\t\t<nd ref=\"2134638188\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust Court\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/203447566\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447566\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<nd ref=\"2134638161\" />\n",
      "\t\t<nd ref=\"2134638153\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust Court\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/203447571\n",
      "\n",
      "<way changeset=\"15393235\" id=\"203447571\" timestamp=\"2013-03-17T09:49:18Z\" uid=\"12434\" user=\"nm7s9\" version=\"2\">\n",
      "\t\t<nd ref=\"2134638182\" />\n",
      "\t\t<nd ref=\"2134638178\" />\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust Court\" />\n",
      "\t\t<tag k=\"oneway\" v=\"yes\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n",
      "\t\n",
      "Check ID online at: http://www.openstreetmap.org/way/210560329\n",
      "\n",
      "<way changeset=\"15393235\" id=\"210560329\" timestamp=\"2013-03-17T09:49:17Z\" uid=\"12434\" user=\"nm7s9\" version=\"1\">\n",
      "\t\t<nd ref=\"2134638315\" />\n",
      "\t\t<nd ref=\"2134638310\" />\n",
      "\t\t<nd ref=\"2134638277\" />\n",
      "\t\t<nd ref=\"2134638249\" />\n",
      "\t\t<nd ref=\"2134638237\" />\n",
      "\t\t<nd ref=\"2134638230\" />\n",
      "\t\t<nd ref=\"2134638224\" />\n",
      "\t\t<nd ref=\"2134638221\" />\n",
      "\t\t<nd ref=\"2134638220\" />\n",
      "\t\t<nd ref=\"2134638223\" />\n",
      "\t\t<nd ref=\"2134638229\" />\n",
      "\t\t<nd ref=\"2134638233\" />\n",
      "\t\t<nd ref=\"2134638243\" />\n",
      "\t\t<nd ref=\"2134638259\" />\n",
      "\t\t<nd ref=\"2134638322\" />\n",
      "\t\t<nd ref=\"2134638403\" />\n",
      "\t\t<nd ref=\"2134638410\" />\n",
      "\t\t<nd ref=\"2134638413\" />\n",
      "\t\t<nd ref=\"2134638416\" />\n",
      "\t\t<nd ref=\"2134638414\" />\n",
      "\t\t<nd ref=\"2134638412\" />\n",
      "\t\t<nd ref=\"2134638407\" />\n",
      "\t\t<nd ref=\"2134638402\" />\n",
      "\t\t<nd ref=\"2134638396\" />\n",
      "\t\t<nd ref=\"2134638390\" />\n",
      "\t\t<nd ref=\"2134638373\" />\n",
      "\t\t<nd ref=\"2134638304\" />\n",
      "\t\t<nd ref=\"2134638257\" />\n",
      "\t\t<nd ref=\"2134638238\" />\n",
      "\t\t<nd ref=\"2134638226\" />\n",
      "\t\t<nd ref=\"2134638210\" />\n",
      "\t\t<nd ref=\"2134638202\" />\n",
      "\t\t<nd ref=\"2134638192\" />\n",
      "\t\t<nd ref=\"2134638185\" />\n",
      "\t\t<nd ref=\"2134638180\" />\n",
      "\t\t<nd ref=\"2134638172\" />\n",
      "\t\t<nd ref=\"2134638170\" />\n",
      "\t\t<tag k=\"name\" v=\"Wanderlust Court\" />\n",
      "\t\t<tag k=\"review\" v=\"no\" />\n",
      "\t\t<tag k=\"source\" v=\"Bing\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t</way>\n"
     ]
    }
   ],
   "source": [
    "find_something(OSM_FILE, 'Wanderlust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'Seven Oaks', 'Seven Oaks Way', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'Padero', 'North Padero Drive', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'Scottyboy', 'Scottyboy Drive', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'Seashore', 'Seashore Drive', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, 'S FLore del Sol', 'S Flore del Sol Street', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "substitute_smth(OSM_FILE, street_types['Avenmue'][0], 'West Fenway Park Avenue', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! Now my cleaning functions are working fine, it seems : )\n",
    "\n",
    "Next step is that I'd have to automate them to apply the necessary changes to batches of the special exceptions that I found. Otherwise I'd have to go through it one-by-one, which is very tedious. \n",
    "\n",
    "For this I will have to classify the information I have into different connected groups. E.g., that all those Elements that need `area=yes` added may be collected together, so I can do one action that will run the same task on them all. In order to be able to group them, I will, however, have to know what they are and what are their specific issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping the Exceptions\n",
    "\n",
    "**DISCLAIMER**: There's one problem with my approach, which is that I developed it with the **truncated version** of the OSM file. Since the decisions how to group the Elements with the specific name value endings was often taken after individually investigating all the returned Elements, it might cause troubles when applied to the complete file. Because there might be instances that have the same ending, however should be treated differently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Many street names have their 'type' at the start, when they are non-english type names\n",
    "other_langs = ['Avenida', 'Via', 'Camino', 'Calle', 'Plaza', 'Calle', 'Vista'] \n",
    "\n",
    "# the following have to be corrected:\n",
    "misspelled = ['Avenmue', 'Driive']\n",
    "shortenings = ['Hwy', 'Mhp', 'Rd']\n",
    "prefixed = ['Avenue']\n",
    "wrong_suffixed = ['North', '(Difficult)', ', Lower', 'S', 'South']\n",
    "# Lower': ['Las Vegas Wash Trail, Lower']\n",
    "# things including 'Trail' somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were found to be actual streets with uncommon name endings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_fine = {'Access' : street_types['Access'],\n",
    "            'Oak' : street_types['Oak'],\n",
    "            'Oasis' : street_types['Oasis'],\n",
    "            'Paseo' : street_types['Paseo'],\n",
    "            'Pines' : street_types['Pines'],\n",
    "            'Cottage' : street_types['Cottage'],\n",
    "            'Point' : street_types['Point'],\n",
    "            'Portico' : street_types['Portico'],\n",
    "            'Reef' : street_types['Reef'],\n",
    "            'Sawtooth' : street_types['Sawtooth'],\n",
    "            'Sierra' : street_types['Sierra'],\n",
    "            'Solano' : street_types['Solano'],\n",
    "            'Star' : street_types['Star']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were found to be living quaters (therefore: `area=yes`), that according to the OSM wiki should have a tag with the `place=suburb` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_area_suburb = {'Homestretch' : street_types['Homestretch'],\n",
    "                  'Homes' : street_types['Homes'],\n",
    "                  'Paradise' : street_types['Paradise'],\n",
    "                  'Somerset' : street_types['Somerset']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following individual buildings recorded as closed ways (therefore: `area=yes` and `building=yes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_area_building = {'Alex' : street_types['Alex']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some kind of areas, so it makes sense to add: `area=yes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_area = {'P' : street_types['P'],\n",
    "            'Wilderness' : street_types['Wilderness']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally these ones represent abbreviations for common street types, and should be expanded to the fully spelled version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "substitute = {'Ave' : street_types['Ave'],\n",
    "              'Hwy' : street_types['Hwy'],\n",
    "              'Rd' : street_types['Rd']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to state here again that these steps of cleaning are not exhaustive. Already in the truncated version there are special cases that I didn't address, and there will be many more when running this file with the full dataset.\n",
    "\n",
    "However, it gave me an insight into the troubles that one encounters when dealing with cleaning data. There are a lot of human generated imprecisions, different mappings and opinions on what to do, different (human generated) inconsistencies already in the reality of the data that gets recorded (e.g. not all streets have a street type at their end, or at all) etc.\n",
    "\n",
    "Therefore I decided that I dove deep enough into this dataset, did my part of cleaning it a bit and learning about the parts involved, and that it's enough with this for now :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here I will apply the cleanings that I have devised, and then I'll move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add area=yes\n",
    "type_dict = add_area\n",
    "\n",
    "for key, value in type_dict.items():\n",
    "    for v in enumerate(value):\n",
    "        name = v[1]\n",
    "        for elem_id in get_id(OSM_FILE, name):\n",
    "            add_smth(OSM_FILE, elem_id, 'area', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes area=yes are already present in this Element.\n"
     ]
    }
   ],
   "source": [
    "# add area=yes, building=yes\n",
    "type_dict = add_area_building\n",
    "\n",
    "for key, value in type_dict.items():\n",
    "    for v in enumerate(value):\n",
    "        name = v[1]\n",
    "        for elem_id in get_id(OSM_FILE, name):\n",
    "            add_smth(OSM_FILE, elem_id, 'area', 'yes')\n",
    "            add_smth(OSM_FILE, elem_id, 'building', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes area=yes are already present in this Element.\n"
     ]
    }
   ],
   "source": [
    "# add area=yes, place=suburb\n",
    "type_dict = add_area_suburb\n",
    "\n",
    "for key, value in type_dict.items():\n",
    "    for v in enumerate(value):\n",
    "        name = v[1]\n",
    "        for elem_id in get_id(OSM_FILE, name):\n",
    "            add_smth(OSM_FILE, elem_id, 'area', 'yes')\n",
    "            add_smth(OSM_FILE, elem_id, 'place', 'suburb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Could scrape data for common US street type abbreviations and add the mappings to the list. E.g. from here: http://pe.usps.gov/text/pub28/28apc_002.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extend street name abbreviations\n",
    "import re\n",
    "map_dict = {'Rd' : 'Road', 'Hwy' : 'Highway', 'Ave' : 'Avenue'}\n",
    "type_dict = substitute\n",
    "street_re = re.compile(r'[^ ]+[ ]', re.IGNORECASE)\n",
    "\n",
    "for key, value in type_dict.items():\n",
    "    for v in enumerate(value):\n",
    "        old_name = v[1]\n",
    "        re_li = re.findall(street_re, old_name)\n",
    "        new_name = ''.join(re_li) + map_dict[key]\n",
    "        substitute_smth(OSM_FILE, old_name, new_name, 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally I will apply the street types I learned I could exclude back onto my original function, to create a new and smaller `street_type` dictionary. This dict will contain the special cases that would need further attention and more thorough and individual cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in all_fine.keys():\n",
    "    if key not in exclude:\n",
    "        exclude.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adapting the function with the newly learned aspects\n",
    "def collect_way_types(filename, expected_types):\n",
    "    street_types = {}\n",
    "    # added these common non-english street names that appear at the beginning rather than the end\n",
    "    non_eng_street_names = ['Avenida', 'Via', 'Camino', 'Calle', 'Vista', 'Placida']\n",
    "    # here are some attributes that I found define non-street ways, so I exclude Elements containing them\n",
    "    non_street_attribs = ['area', 'building', 'amenity', 'golf', 'railway']\n",
    "    for event, elem in ET.iterparse(filename, events=('start',)):\n",
    "        flag = False\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if (tag.attrib['k'] in non_street_attribs) and (tag.attrib['v'] != 'no'):\n",
    "                        flag = True\n",
    "                for non_eng_name in non_eng_street_names:\n",
    "                    # if a street starts with one of the non-eng names, it is excluded\n",
    "                    if tag.attrib['v'].startswith(non_eng_name):\n",
    "                        flag = True\n",
    "                \n",
    "            if flag == False:\n",
    "                for tag in elem.iter('tag'):\n",
    "                    if tag.attrib['k'] == 'name':\n",
    "                        street_name = tag.attrib['v']\n",
    "                        audit_street_type(street_types, expected_types, street_name)                       \n",
    "    return street_types\n",
    "\n",
    "street_types = collect_way_types(OSM_FILE, exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(street_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But actually this is all mostly crap, because it's little single adaptations that don't make a big difference. Even if I'd work this file down to zero - I realized that this is only a truncated file! Therefore, there are surely many more such single-cases, that would need personal attendance (that I am not willing to give for much longer)...\n",
    "\n",
    "So, and that's also my task as a programmer, I shall abstract more and make some functions that do many cleanings.\n",
    "And then that's it.\n",
    "Doesn't make it clean, but makes it clea**er**.\n",
    "\n",
    "Which is maybe good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I must say also that I don't feel too bad about doing it, because I was also still exploring the city a bit, and also exploring OSM a bit, and XML and python and all.\n",
    "So it's not wasted time and effort, but I think of those things it's enough now, and it's time to wrap it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merging changes with original XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_changes = ET.ElementTree(file=OSM_FILE)\n",
    "chang_root = tree_changes.getroot()\n",
    "changed_elems = chang_root.findall('way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'changeset': '4250464', 'uid': '20587', 'timestamp': '2010-03-27T22:52:27Z', 'version': '2', 'user': 'balrog-kun', 'id': '14278349'}\n",
      "<way changeset=\"4250464\" id=\"14278349\" timestamp=\"2010-03-27T22:52:27Z\" uid=\"20587\" user=\"balrog-kun\" version=\"2\">\n",
      "\t\t<nd ref=\"137032566\" />\n",
      "\t\t<nd ref=\"137032567\" />\n",
      "\t\t<tag k=\"name\" v=\"Dallas\" />\n",
      "\t\t<tag k=\"name_1\" v=\"Dallas Court\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t\t<tag k=\"tiger:cfcc\" v=\"A41\" />\n",
      "\t\t<tag k=\"tiger:tlid\" v=\"201902597\" />\n",
      "\t\t<tag k=\"tiger:county\" v=\"Clark, NV\" />\n",
      "\t\t<tag k=\"tiger:source\" v=\"tiger_import_dch_v0.6_20070813\" />\n",
      "\t\t<tag k=\"tiger:reviewed\" v=\"no\" />\n",
      "\t\t<tag k=\"tiger:name_base\" v=\"Dallas\" />\n",
      "\t\t<tag k=\"tiger:separated\" v=\"no\" />\n",
      "\t\t<tag k=\"tiger:name_base_1\" v=\"Dallas\" />\n",
      "\t\t<tag k=\"tiger:name_type_1\" v=\"Ct\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "try_elem = chang_root[0]\n",
    "print try_elem.attrib\n",
    "ET.dump(try_elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- maybe removing all tags\n",
    "- reinserting the new ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I got some xml elements saved in this findall() returned list, that can now be nicely queried :)\n",
    "\n",
    "Maybe this could have saved me lots of work? Well, now I have this, maybe I can work with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changes_dict = {}\n",
    "for elem in changed_elems:\n",
    "    changes_dict[elem.attrib['id']] = elem        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2106"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(changes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the following function I'll be merging the changes with the original Element Tree and create a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORIG_FILE = 'LV_truncated.osm'\n",
    "NEW_FILE = 'LV_applied_changes.osm'\n",
    "\n",
    "def merge_changes(osm_file, changes):\n",
    "    '''Merges the changes applied on the street names back into the original OSM file structure, creating a new file.'''\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'start' and elem.tag == 'way':\n",
    "            current_id = elem.attrib['id']\n",
    "            if current_id in changes.keys():\n",
    "                elem = changes[current_id]\n",
    "        if event == 'end':\n",
    "            yield elem\n",
    "            root.clear()\n",
    "                \n",
    "with open(NEW_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "    for i, element in enumerate(merge_changes(ORIG_FILE, changes_dict)):\n",
    "        output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check ID online at: http://www.openstreetmap.org/way/226135717\n",
      "\n",
      "<way changeset=\"16595288\" id=\"226135717\" timestamp=\"2013-06-17T20:05:18Z\" uid=\"3392\" user=\"SimMoonXP\" version=\"1\">\n",
      "\t\t<nd ref=\"137538171\" />\n",
      "\t\t<nd ref=\"276935081\" />\n",
      "\t\t<nd ref=\"2121261466\" />\n",
      "\t\t<tag k=\"name\" v=\"Eldorado Lane\" />\n",
      "\t\t<tag k=\"lanes\" v=\"2\" />\n",
      "\t\t<tag k=\"highway\" v=\"residential\" />\n",
      "\t\t<tag k=\"maxspeed\" v=\"25 mph\" />\n",
      "\t\t<tag k=\"tiger:cfcc\" v=\"A41\" />\n",
      "\t\t<tag k=\"tiger:county\" v=\"Clark, NV\" />\n",
      "\t\t<tag k=\"tiger:zip_left\" v=\"89123\" />\n",
      "\t\t<tag k=\"tiger:name_base\" v=\"Eldorado\" />\n",
      "\t\t<tag k=\"tiger:name_type\" v=\"Ln\" />\n",
      "\t\t<tag k=\"tiger:zip_right\" v=\"89123\" />\n",
      "\t\t<tag k=\"tiger:name_direction_prefix\" v=\"E\" />\n",
      "\t</way>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "find_something(NEW_FILE, 'Eldorado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting to MongoDB\n",
    "\n",
    "Now, after having performed some cleaning action, I'll edit the data so I'll be able to transfer it into MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code taken from Lesson 6 and adapted to my situation\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    # you should process only 2 types of top level tags: \"node\" and \"way\"\n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        node['created'] = {}\n",
    "        node['visible'] = 'true'\n",
    "        node['type'] = element.tag\n",
    "        for key, value in element.attrib.iteritems():\n",
    "            if key in CREATED:\n",
    "                node['created'][key] = value\n",
    "            elif key != 'lat' and key != 'lon':\n",
    "                node[key] = value\n",
    "        try:\n",
    "            node['pos'] = [float(element.attrib['lat']), float(element.attrib['lon'])]\n",
    "        except:\n",
    "            pass\n",
    "        if element.tag == 'way':\n",
    "            node['node_refs'] = {}\n",
    "            nd_list = []\n",
    "            for nd in element.iter('nd'):\n",
    "                nd_list.append(nd.attrib['ref'])\n",
    "            node['node_refs'] = nd_list\n",
    "\n",
    "        # creating the additional dicts\n",
    "        for child in element:\n",
    "            if child.tag == 'tag':\n",
    "                attrib_key = child.attrib['k']\n",
    "                attrib_value = child.attrib['v']\n",
    "                if re.search(r'(\\w+:){2}', attrib_key):\n",
    "                    continue\n",
    "                if re.search(r':', attrib_key):\n",
    "                    separate_by_colon_re = re.compile(r'([\\w]+[^:\\n])')\n",
    "                    key_parts_list = re.findall(separate_by_colon_re, attrib_key)\n",
    "                    main_key = key_parts_list.pop(0)\n",
    "                    # removing the main key\n",
    "                    if len(key_parts_list) == 1:\n",
    "                        secondary_key = key_parts_list.pop(0)\n",
    "                        if main_key == 'addr':\n",
    "                            if 'address' in node:\n",
    "                                node['address'][secondary_key] = attrib_value\n",
    "                            else:\n",
    "                                node['address'] = {}\n",
    "                                node['address'][secondary_key] = attrib_value\n",
    "                        else:\n",
    "                            if main_key in node and type(node[main_key]) == dict:\n",
    "                                node[main_key][secondary_key] = attrib_value\n",
    "                            ### NOTE: Some keys I create with regex as keys for dict might already exist as\n",
    "                            ### keys one level up. Therefore I added this to not lose the information from there\n",
    "                            else:\n",
    "                                main_key = main_key+'dict'\n",
    "                                node[main_key] = {}\n",
    "                                node[main_key][secondary_key] = attrib_value\n",
    "                            if main_key not in node:\n",
    "                                node[main_key] = {}\n",
    "                                node[main_key][secondary_key] = attrib_value\n",
    "                else:\n",
    "                    node[attrib_key] = attrib_value\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "            for _, element in ET.iterparse(file_in):\n",
    "                    el = shape_element(element)\n",
    "                    if el:\n",
    "                            data.append(el)\n",
    "                            if pretty:\n",
    "                                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                            else:\n",
    "                                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_struct = process_map('las-vegas_nevada.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': {'changeset': '21953362',\n",
      "             'timestamp': '2014-04-26T12:32:58Z',\n",
      "             'uid': '85673',\n",
      "             'user': 'Bored',\n",
      "             'version': '8'},\n",
      " 'id': '31551114',\n",
      " 'is_in': 'Nevada',\n",
      " 'is_indict': {'continent': 'North America'},\n",
      " 'name': 'Las Vegas',\n",
      " 'namedict': {'zh': u'\\u62c9\\u65af\\u7ef4\\u52a0\\u65af'},\n",
      " 'place': 'city',\n",
      " 'population': '567641',\n",
      " 'pos': [36.1662859, -115.149225],\n",
      " 'type': 'node',\n",
      " 'visible': 'true'}\n"
     ]
    }
   ],
   "source": [
    "# take a look at the data\n",
    "pprint.pprint(json_struct[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': {'changeset': '15375615',\n",
      "             'timestamp': '2013-03-15T17:14:07Z',\n",
      "             'uid': '12434',\n",
      "             'user': 'nm7s9',\n",
      "             'version': '3'},\n",
      " 'highway': 'turning_circle',\n",
      " 'id': '137225011',\n",
      " 'pos': [36.231476, -115.17462],\n",
      " 'type': 'node',\n",
      " 'visible': 'true'}\n"
     ]
    }
   ],
   "source": [
    "# doing a random query\n",
    "count = 0\n",
    "for i in json_struct:\n",
    "    if i['id'] == '137225011':\n",
    "        pprint.pprint(json_struct[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After finally having the data saved in an exported .json file, I was ready to import it to MongoDB. For this I used the mongoimport command in the terminal, after installing MongoDB on my computer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Overview using MongoDB\n",
    "\n",
    "Here are some glimpses into the commands I ran on my data, using pymongo, but also the mongodb shell.\n",
    "\n",
    "As references for these look-ups I used the respective docs for **pymongo** and the **mongodb shell** found here: https://docs.mongodb.org/getting-started/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> db.lasvegas.stats({ dbStats: 1, scale: 1 })\n",
    "{\n",
    "\t\"ns\" : \"udacity.lasvegas\",\n",
    "\t\"count\" : 916706,\n",
    "\t\"size\" : 234245793,\n",
    "\t\"avgObjSize\" : 255, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a (truncated) result of the stats that the `db.collection.stats()` command run in the mongodb shell returns.\n",
    "The size of the data is presented in **bytes** (to change this, the `scale` parameter can be set e.g. to `2048` to return the result in MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the stats regarding the amount of posts per user for the top users:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> db.lasvegas.aggregate([{\"$group\":{ \"_id\":\"$created.user\", \"count\":{\"$sum\":1}}},{\"$sort\":{\"count\":-1}},{\"$limit\":10}]).pretty()\n",
    "{ \"_id\" : \"alimamo\", \"count\" : 253804 }\n",
    "{ \"_id\" : \"woodpeck_fixbot\", \"count\" : 75622 }\n",
    "{ \"_id\" : \"alecdhuse\", \"count\" : 66729 }\n",
    "{ \"_id\" : \"abellao\", \"count\" : 49629 }\n",
    "{ \"_id\" : \"gMitchellD\", \"count\" : 47377 }\n",
    "{ \"_id\" : \"robgeb\", \"count\" : 43289 }\n",
    "{ \"_id\" : \"nmixter\", \"count\" : 40250 }\n",
    "{ \"_id\" : \"MojaveNC\", \"count\" : 30173 }\n",
    "{ \"_id\" : \"nm7s9\", \"count\" : 26712 }\n",
    "{ \"_id\" : \"balrog-kun\", \"count\" : 15051 }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to get to know how to look for specific values. The following query returns the values of all _highway_ fields in all _documents_ of the Las Vegas data:\n",
    "\n",
    "(I chose this query, because the random query I ran further up returned me a wonderfully fitting `turning_circle` in \"Godbey Court\" :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> db.lasvegas.distinct(\"highway\", {highway : {$exists : true}})\n",
    "[\n",
    "\t\"motorway_junction\",\n",
    "\t\"turning_circle\",\n",
    "\t\"traffic_signals\",\n",
    "\t\"crossing\",\n",
    "\t\"passing_place\",\n",
    "\t\"mini_roundabout\",\n",
    "\t\"stop\",\n",
    "\t\"turning_loop\",\n",
    "\t\"overhead_sign\",\n",
    "\t\"trailhead\",\n",
    "\t\"bus_stop\",\n",
    "\t\"street_lamp\",\n",
    "\t\"give_way\",\n",
    "\t\"intersection\",\n",
    "\t\"elevator\",\n",
    "\t\"motorway\",\n",
    "\t\"residential\",\n",
    "\t\"service\",\n",
    "\t\"secondary\",\n",
    "\t\"track\",\n",
    "\t\"tertiary\",\n",
    "\t\"motorway_link\",\n",
    "\t\"footway\",\n",
    "\t\"road\",\n",
    "\t\"unclassified\",\n",
    "\t\"path\",\n",
    "\t\"secondary_link\",\n",
    "\t\"trunk_link\",\n",
    "\t\"trunk\",\n",
    "\t\"proposed\",\n",
    "\t\"pedestrian\",\n",
    "\t\"living_street\",\n",
    "\t\"tertiary_link\",\n",
    "\t\"primary\",\n",
    "\t\"steps\",\n",
    "\t\"cycleway\",\n",
    "\t\"raceway\",\n",
    "\t\"construction\",\n",
    "\t\"bridleway\",\n",
    "\t\"escalator\",\n",
    "\t\"primary_link\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sticking with `turning_circle`s, I've used the cursor-query results to see how many of similar nodes referencing a `turning_circle` exist in the dataset:\n",
    "\n",
    "```\n",
    "> db.lasvegas.find({'highway': 'turning_circle'}).count()\n",
    "6800\n",
    "```\n",
    "\n",
    "That's a lot :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a short look back into the aspect of the dataset that I tried to clean a little bit during my exploration, I've constructed this query using a regex that matches any value of the `name` fields that ends with a \".\" (which might indicate an abbreviated street name).\n",
    "\n",
    "This is the result:\n",
    "\n",
    "```\n",
    "> db.lasvegas.find({'name': { $regex: /( \\w+\\.)$/, $options: '<options>' } }).count()\n",
    "13\n",
    "```\n",
    "\n",
    "It might be interesting to take a look at these 13 documents and eventually write a function to clean them. 13 documents does actually sound manageable :)\n",
    "A short peek (by removing the `.count()` and running it again) already shows that most of them denote a fast-food chain, and some might be interesting for further, more focused street type cleaning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I've taken the chance of this DAND project to explore Las Vegas in a for me very interesting way. I surely took quite some detours regarding the aim of this project, however this offered me on one hand some beautiful discoveries, and on the other hand a lot of learning to handle XML (and especially OSM) data, and gave me some insight into how a process of auditing and cleaning a database might look like.\n",
    "\n",
    "### Overview of the Data\n",
    "\n",
    "Some initial statistics can be found at the top of this document, that were performed using python analysis of the file I used and the ElementTree that was built from it.\n",
    "\n",
    "Later there is some more statistical analysis performed with the mongodb shell at the end of the document, before the Conclusion.\n",
    "\n",
    "### Problems encountered in my map\n",
    "\n",
    "Throughout the description of my process and the steps that I took, I keep explaining the problems that I encountered. They were manyfold! Some are caused by the users who were entering the data, some others by me, my initial lack of knowledge, and some inefficient approaches that I took.\n",
    "\n",
    "- street names were not saved in `addr:street` but in the `name` attribute, that also contains names of other places\n",
    "- 'way' tags can also be structures called 'closed ways' that represent e.g. buildings. often the suggested flags to indicate this are not present in the tags\n",
    "- trying to exclude speciality tags on a case-by-case basis is very ineffective, especially because it does not account for a changing dataset\n",
    "- ...\n",
    "\n",
    "I've learned not to go down paths of cleaning individual examples, and at the same time that there will be many of them to find if I'm dealing with human-inputted data.\n",
    "\n",
    "### Other ideas about the dataset\n",
    "\n",
    "A lot of my time working on my dataset I spent on learning about and interacting with the XML structure's Element Tree. There's more to do there:\n",
    "\n",
    "- adding flagging tags with appropriate attributes (e.g. `area=yes`) to those 'way' tags that are **closed ways**\n",
    "- adapt the `audit_street_type()` function to return a more useful street type dictionary that excludes speciality cases\n",
    "- scrape the TIGER data online to extract a valid mapping of street type abbreviations to their full-length versions, then use it for a mapping\n",
    "\n",
    "Then it could be very interesting to explore the data more with MongoDB. There are many different ways of creating cursor objects (with different operators and pipelines), that can allow a relatively easy and efficient way to analyze the dataset. Probably easier than it was trying to work it with the ET module. As a short immediate idea, I could adapt the regex pattern or add logical operators to exclude the fast-food chain from the results, take a closer look at the documents returned in the cursor object, and eventually consider cleaning it there.\n",
    "\n",
    "---\n",
    "\n",
    "However, I believe that I've worked enough on this project, so I will not dive into these possible further steps now.\n",
    "I hope that you'll have a bit of fun or an interesting time looking into my project, and am looking forward to your feedback! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
